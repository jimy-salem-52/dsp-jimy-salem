{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmsle(y_test: np.ndarray, y_pred: np.ndarray, precision: int = 2) -> float:\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "    return round(rmsle, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df_train = pd.read_csv(r\"C:\\Users\\SADEK COMPUTER\\Desktop\\Epita\\01 - Semester 2\\Data Science Production\\Github Assignment\\dsp-jimy-salem\\data\\train.csv.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Normal' 'Abnorml' 'Partial' 'AdjLand' 'Alloca' 'Family']\n"
     ]
    }
   ],
   "source": [
    "unique_salecondition = housing_df_train[\"SaleCondition\"].unique()\n",
    "print (unique_salecondition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The housing test shape is (1459, 80)\n",
      "The housing train shape is (1460, 81)\n"
     ]
    }
   ],
   "source": [
    "housing_df_test = pd.read_csv(r\"C:\\Users\\SADEK COMPUTER\\Desktop\\Epita\\01 - Semester 2\\Data Science Production\\Github Assignment\\dsp-jimy-salem\\data\\test.csv.xls\")\n",
    "\n",
    "print (f\"The housing test shape is {housing_df_test.shape}\")\n",
    "print(f\"The housing train shape is {housing_df_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
       "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
       "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
       "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
       "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
       "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0       0      6    2010        WD         Normal  \n",
       "1   12500      6    2010        WD         Normal  \n",
       "2       0      3    2010        WD         Normal  \n",
       "3       0      6    2010        WD         Normal  \n",
       "4       0      1    2010        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pave', 'Grvl'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_street = housing_df_test[\"Street\"].unique()\n",
    "unique_street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
      "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
      "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
      "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
      "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
      "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
      "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
      "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
      "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
      "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
      "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
      "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
      "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
      "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
      "       'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n",
      "\n",
      "The train has a difference  of ['SalePrice'] from the test data\n"
     ]
    }
   ],
   "source": [
    "column_names_test = housing_df_test.columns\n",
    "column_names_train = housing_df_train.columns\n",
    "#Train has more columns\n",
    "print(column_names_train)\n",
    "print()\n",
    "diff_columns = [col for col in housing_df_train.columns if col not in housing_df_test.columns]\n",
    "print(f\"The train has a difference  of {diff_columns} from the test data\")\n",
    "# the indication here is that we need to predict the sale price using modeling for the train data and then compare it with the y  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Training Data \n",
    "\n",
    "To goal is to train the model on the training data to evaluate the prediction for the testing data and do the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                  0\n",
      "MSSubClass          0\n",
      "MSZoning            0\n",
      "LotFrontage       259\n",
      "LotArea             0\n",
      "Street              0\n",
      "Alley            1369\n",
      "LotShape            0\n",
      "LandContour         0\n",
      "Utilities           0\n",
      "LotConfig           0\n",
      "LandSlope           0\n",
      "Neighborhood        0\n",
      "Condition1          0\n",
      "Condition2          0\n",
      "BldgType            0\n",
      "HouseStyle          0\n",
      "OverallQual         0\n",
      "OverallCond         0\n",
      "YearBuilt           0\n",
      "YearRemodAdd        0\n",
      "RoofStyle           0\n",
      "RoofMatl            0\n",
      "Exterior1st         0\n",
      "Exterior2nd         0\n",
      "MasVnrType        872\n",
      "MasVnrArea          8\n",
      "ExterQual           0\n",
      "ExterCond           0\n",
      "Foundation          0\n",
      "BsmtQual           37\n",
      "BsmtCond           37\n",
      "BsmtExposure       38\n",
      "BsmtFinType1       37\n",
      "BsmtFinSF1          0\n",
      "BsmtFinType2       38\n",
      "BsmtFinSF2          0\n",
      "BsmtUnfSF           0\n",
      "TotalBsmtSF         0\n",
      "Heating             0\n",
      "HeatingQC           0\n",
      "CentralAir          0\n",
      "Electrical          1\n",
      "1stFlrSF            0\n",
      "2ndFlrSF            0\n",
      "LowQualFinSF        0\n",
      "GrLivArea           0\n",
      "BsmtFullBath        0\n",
      "BsmtHalfBath        0\n",
      "FullBath            0\n",
      "HalfBath            0\n",
      "BedroomAbvGr        0\n",
      "KitchenAbvGr        0\n",
      "KitchenQual         0\n",
      "TotRmsAbvGrd        0\n",
      "Functional          0\n",
      "Fireplaces          0\n",
      "FireplaceQu       690\n",
      "GarageType         81\n",
      "GarageYrBlt        81\n",
      "GarageFinish       81\n",
      "GarageCars          0\n",
      "GarageArea          0\n",
      "GarageQual         81\n",
      "GarageCond         81\n",
      "PavedDrive          0\n",
      "WoodDeckSF          0\n",
      "OpenPorchSF         0\n",
      "EnclosedPorch       0\n",
      "3SsnPorch           0\n",
      "ScreenPorch         0\n",
      "PoolArea            0\n",
      "PoolQC           1453\n",
      "Fence            1179\n",
      "MiscFeature      1406\n",
      "MiscVal             0\n",
      "MoSold              0\n",
      "YrSold              0\n",
      "SaleType            0\n",
      "SaleCondition       0\n",
      "SalePrice           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#The housing train shape is (1460, 81)\n",
    "null_count = housing_df_train.isnull().sum()\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print (null_count)\n",
    "\n",
    "#Avoid Alley, PoolQC, Fence, MiscFeature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 6)\n"
     ]
    }
   ],
   "source": [
    "X_trial = housing_df_train.copy()\n",
    "\n",
    "y = X_trial[\"SalePrice\"]\n",
    "X_trial = X_trial.drop ([\"Id\", \"PoolQC\", \"Fence\", \"MiscFeature\", \"Alley\", \"FireplaceQu\", \"SalePrice\"], axis=1)\n",
    "\n",
    "X_trial = X_trial [[\"LotArea\", \"Neighborhood\", \"TotalBsmtSF\", \"GrLivArea\",\"BldgType\",\"GarageArea\"]]\n",
    "X_trial.head()\n",
    "\n",
    "print (X_trial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CollgCr' 'Veenker' 'Crawfor' 'NoRidge' 'Mitchel' 'Somerst' 'NWAmes'\n",
      " 'OldTown' 'BrkSide' 'Sawyer' 'NridgHt' 'NAmes' 'SawyerW' 'IDOTRR'\n",
      " 'MeadowV' 'Edwards' 'Timber' 'Gilbert' 'StoneBr' 'ClearCr' 'NPkVill'\n",
      " 'Blmngtn' 'BrDale' 'SWISU' 'Blueste']\n",
      "\n",
      "Index(['LotArea', 'Neighborhood', 'TotalBsmtSF', 'GrLivArea', 'BldgType',\n",
      "       'GarageArea'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X = X_trial.copy() #,\"TotalBsmtSF\", \"SaleCondition\"]]\n",
    "\n",
    "neighborhood_values = X[\"Neighborhood\"].unique()\n",
    "print(neighborhood_values)\n",
    "print()\n",
    "building_type = X['BldgType'].unique()\n",
    "print (X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: SalePrice, dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    208500\n",
       "1    181500\n",
       "2    223500\n",
       "3    140000\n",
       "4    250000\n",
       "Name: SalePrice, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity checking\n",
    "zero_value = y [y<=0]\n",
    "print(zero_value)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\SADEK COMPUTER\\Desktop\\Epita\\01 - Semester 2\\Data Science Production\\Github Assignment\\dsp-jimy-salem\\models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SADEK COMPUTER\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorical_features = ['Neighborhood', 'BldgType']\n",
    "onehot_encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "\n",
    "X_train_categorical = onehot_encoder.fit_transform(X_train[categorical_features])\n",
    "joblib.dump (onehot_encoder, os.path.join (path, \"one_hot_encoder.joblib\"))\n",
    "\n",
    "X_test_categorical = onehot_encoder.transform(X_test[categorical_features])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.drop(categorical_features, axis=1))\n",
    "X_test_scaled = scaler.transform(X_test.drop(categorical_features, axis=1))\n",
    "joblib.dump (scaler, os.path.join (path,\"scaler.joblib\"))\n",
    "\n",
    "X_train_final = np.hstack((X_train_scaled, X_train_categorical))\n",
    "X_test_final = np.hstack((X_test_scaled, X_test_categorical))\n",
    "\n",
    "print(X_train_final.shape)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_final, y_train)\n",
    "\n",
    "#first joblib\n",
    "joblib.dump (model, os.path.join (path,'model.joblib'))\n",
    "\n",
    "y_pred = model.predict(X_test_final)\n",
    "\n",
    "y_pred = np.clip(y_pred, 0, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print (compute_rmsle(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(y, columns=['SalePrice'])\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=['PredictedSalePrice'])\n",
    "result_df = pd.concat([y_df, y_pred_df], axis=1)\n",
    "X_train_df = pd.DataFrame(X_train_final)\n",
    "X_test_df = pd.DataFrame(X_test_final)\n",
    "combined_df = pd.concat([X_train_df, X_test_df])\n",
    "\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "result_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#It didn't work elseway\n",
    "combined_df.columns = combined_df.columns.astype(str)\n",
    "result_df.columns = result_df.columns.astype(str)\n",
    "\n",
    "processed_df = pd.concat([combined_df, result_df], axis =1)\n",
    "processed_df.to_parquet('C:/Users/SADEK COMPUTER/Desktop/Epita/01 - Semester 2/Data Science Production/Github Assignment/dsp-jimy-salem/notebooks/processed_df.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'processed_df.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m correctly_processed_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocessed_df.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#None means the assertion was successful\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m (pd\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39massert_frame_equal(processed_df, correctly_processed_df))\n",
      "File \u001b[1;32mc:\\Users\\SADEK COMPUTER\\.conda\\envs\\ml\\lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    668\u001b[0m     path,\n\u001b[0;32m    669\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    670\u001b[0m     filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    671\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    672\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    673\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    674\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    676\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\SADEK COMPUTER\\.conda\\envs\\ml\\lib\\site-packages\\pandas\\io\\parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    275\u001b[0m         path_or_handle,\n\u001b[0;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    280\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SADEK COMPUTER\\.conda\\envs\\ml\\lib\\site-packages\\pandas\\io\\parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\SADEK COMPUTER\\.conda\\envs\\ml\\lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'processed_df.parquet'"
     ]
    }
   ],
   "source": [
    "correctly_processed_df = pd.read_parquet('processed_df.parquet')\n",
    "#None means the assertion was successful\n",
    "print (pd.testing.assert_frame_equal(processed_df, correctly_processed_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation/Model Inference\n",
    "\n",
    "Due to the fact my code is not well structured from the begining, I will add both ideas and proceed with models folder and joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n"
     ]
    }
   ],
   "source": [
    "print (len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"LotArea\", \"Neighborhood\", \"TotalBsmtSF\", \"GrLivArea\",\"BldgType\", \"TotalBsmtSF\",\"GarageArea\"\n",
    "feature_chosen_test = housing_df_test[[\"LotArea\" , \"Neighborhood\", \"TotalBsmtSF\", \"GrLivArea\",\"BldgType\",\"GarageArea\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotArea         0\n",
      "Neighborhood    0\n",
      "TotalBsmtSF     1\n",
      "GrLivArea       0\n",
      "BldgType        0\n",
      "GarageArea      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_counts = feature_chosen_test.isnull().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_chosen_test = feature_chosen_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotArea         0\n",
      "Neighborhood    0\n",
      "TotalBsmtSF     0\n",
      "GrLivArea       0\n",
      "BldgType        0\n",
      "GarageArea      0\n",
      "dtype: int64\n",
      "(1457, 6)\n"
     ]
    }
   ],
   "source": [
    "recount_null = feature_chosen_test.isnull().sum()\n",
    "print(recount_null)\n",
    "\n",
    "print (feature_chosen_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = ['Neighborhood', 'BldgType']\n",
    "encoder_unloaded = joblib.load(os.path.join (path, 'one_hot_encoder.joblib'))\n",
    "\n",
    "encoded_features = encoder_unloaded.fit_transform(feature_chosen_test[columns_to_encode])\n",
    "categories = encoder_unloaded.categories_\n",
    "\n",
    "encoded_columns = [f\"{column}_{category}\" for column, category_list in zip(columns_to_encode, categories) for category in category_list[1:]]\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoded_columns)\n",
    "\n",
    "encoded_df.head()\n",
    "features = feature_chosen_test.copy()\n",
    "\n",
    "feature_chosen_test.drop(columns=columns_to_encode, inplace=True)\n",
    "feature_chosen_test = pd.concat([feature_chosen_test, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1455, 32)\n",
      "1455\n"
     ]
    }
   ],
   "source": [
    "model_unload = joblib.load(os.path.join (path, 'model.joblib'))# for the sake of joblib\n",
    "feature_chosen_test.dropna(inplace=True)\n",
    "\n",
    "scaler_unloaded = joblib.load(os.path.join(path, 'scaler.joblib'))\n",
    "\n",
    "print (feature_chosen_test.shape)\n",
    "y_pred_test = model_unload.predict(scaler_unloaded.fit_transform(feature_chosen_test))#scaler_unloaded.fit_transform(feature_chosen_test))\n",
    "\n",
    "y_pred_test = np.abs(y_pred_test)\n",
    "\n",
    "print(len(y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.01\n"
     ]
    }
   ],
   "source": [
    "#5 were removed, if they were critical points it will afect \n",
    "y_truncated = y[:len(y_pred_test)]\n",
    "\n",
    "rmsle = compute_rmsle(y_truncated, y_pred_test)\n",
    "print(rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Refactoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea behind the code:\n",
    "1. Feature_selection will get the whole original data and return:\n",
    "    \n",
    "    train data: the dataset will remove all the null values containing the features chosen\n",
    "    \n",
    "    test data: Only the needed features without null values \n",
    "\n",
    "Now this will clearly provide a dataset with only the features to continue the whole other part \n",
    "\n",
    "2. Train_split_func will be passed only the needed data after training and splitting:\n",
    "\n",
    "    Only Conducted for the training Data: train test split after choosing the y (Target variable)\n",
    "\n",
    "3. Hot Encoding Function: this will hot encode categorical features after being provided the dataframe containing only the function \n",
    "\n",
    "    Train Data: train, test split will be done followed by hot encoding \n",
    "\n",
    "    Test Data: After having the selected features we will be doing a hot encoding over categorical variables \n",
    "\n",
    "4. Scaling: Similar to hot encoding step but with scaling\n",
    "\n",
    "For Train Data: we can simply only do the encoding and testing \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection (data: pd.DataFrame, is_test: bool, features: list, y_out: list):\n",
    "    #in our case features gonna be [\"LotArea\", \"Neighborhood\", \"TotalBsmtSF\", \"GrLivArea\", \"BldgType\", \"GarageArea\"]\n",
    "    #y is gonna be [\"SalePrice\"]\n",
    "\n",
    "    if is_test == False: #this is the train data with sales price\n",
    "        feature_selection = data[features + y_out]\n",
    "        feature_selection.dropna(subset=features, inplace=True)\n",
    "        X = feature_selection [features]\n",
    "        y = feature_selection [y_out]\n",
    "        return pd.concat ([X, y], axis = 1)\n",
    "    else:\n",
    "        feature_selection = data[features]\n",
    "        feature_selection.dropna(subset=features, inplace=True)\n",
    "    return feature_selection\n",
    "\n",
    "def train_split_func(data: pd.DataFrame, is_test: bool, y_out: list):\n",
    "    if is_test == False:\n",
    "        y = data[y_out]\n",
    "        X = data.drop(columns=y_out, axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def hot_encoding_func(data: pd.DataFrame, is_test: bool, categorical_features: list, y_out: list):\n",
    "    onehot_encoder = joblib.load(os.path.join(path, 'one_hot_encoder.joblib'))\n",
    "    if is_test == False:\n",
    "        X_train, X_test, y_train, y_test = train_split_func(data, is_test, y_out)\n",
    "        X_train_categorical = onehot_encoder.fit_transform(X_train[categorical_features])\n",
    "        X_test_categorical = onehot_encoder.transform(X_test[categorical_features])\n",
    "        return X_train_categorical, X_test_categorical, y_train, y_test\n",
    "    else:\n",
    "        if categorical_features:\n",
    "            encoded_features = onehot_encoder.transform(data[categorical_features])\n",
    "            categories = onehot_encoder.categories_\n",
    "            encoded_columns = [f\"{column}_{category}\" for column, category_list in zip(categorical_features, categories) for category in category_list[1:]]\n",
    "            encoded_df = pd.DataFrame(encoded_features, columns=encoded_columns)\n",
    "            data.drop(columns=categorical_features, inplace=True)\n",
    "            return pd.concat([data, encoded_df], axis=1)\n",
    "        else:\n",
    "            return data\n",
    "\n",
    "def scaling_func (data: pd.DataFrame, is_test: bool, categorical_features: list, y_out: list):\n",
    "    scaler = joblib.load(os.path.join (path, 'scaler.joblib'))\n",
    "    #categorical_features = ['Neighborhood', 'BldgType']\n",
    "    if is_test == False:\n",
    "        X_train, X_test, y_train, y_test = train_split_func (data, is_test, y_out)\n",
    "        X_train_scaled = scaler.fit_transform(X_train.drop(categorical_features, axis=1))\n",
    "        X_test_scaled = scaler.transform(X_test.drop(categorical_features, axis=1))\n",
    "        return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "    else:\n",
    "        data.dropna(inplace=True)\n",
    "        data = scaler.fit_transform(data)\n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before Using the Preprocessing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model\n",
    "\n",
    "In this step, it is obvious that the train training set is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data: pd.DataFrame) -> dict[str, str]:\n",
    "    result = {}\n",
    "    #this step is crucial to drop all the NA \n",
    "    feature_selection = data[[\"LotArea\", \"Neighborhood\", \"TotalBsmtSF\", \"GrLivArea\", \"BldgType\", \"GarageArea\", \"SalePrice\"]]\n",
    "    feature_selection.dropna(subset=[\"LotArea\", \"Neighborhood\", \"TotalBsmtSF\", \"GrLivArea\", \"BldgType\", \"GarageArea\"], inplace=True)\n",
    "\n",
    "    X = feature_selection [[\"LotArea\", \"Neighborhood\", \"TotalBsmtSF\", \"GrLivArea\",\"BldgType\",\"GarageArea\"]]\n",
    "    y = feature_selection [[\"SalePrice\"]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    #encoding \n",
    "    onehot_encoder = joblib.load(os.path.join (path, 'one_hot_encoder.joblib'))\n",
    "    categorical_features = ['Neighborhood', 'BldgType']\n",
    "    X_train_categorical = onehot_encoder.fit_transform(X_train[categorical_features])\n",
    "    X_test_categorical = onehot_encoder.transform(X_test[categorical_features])\n",
    "    \n",
    "    #scaling \n",
    "    scaler = joblib.load(os.path.join (path, 'scaler.joblib'))\n",
    "    X_train_scaled = scaler.fit_transform(X_train.drop(categorical_features, axis=1))\n",
    "    X_test_scaled = scaler.transform(X_test.drop(categorical_features, axis=1))\n",
    "\n",
    "    #finalizing, fitting and predicting  \n",
    "    X_train_final = np.hstack((X_train_scaled, X_train_categorical))\n",
    "    X_test_final = np.hstack((X_test_scaled, X_test_categorical))\n",
    "\n",
    "    model = joblib.load(os.path.join (path, 'model.joblib'))\n",
    "    model.fit(X_train_final, y_train)\n",
    "    y_pred = model.predict(X_test_final)\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "\n",
    "    result['rmse'] = compute_rmsle(y_test, y_pred)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SADEK COMPUTER\\AppData\\Local\\Temp\\ipykernel_15428\\1005047882.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_selection.dropna(subset=[\"LotArea\", \"Neighborhood\", \"TotalBsmtSF\", \"GrLivArea\", \"BldgType\", \"GarageArea\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#let's try it\n",
    "print (build_model (housing_df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make_prediction\n",
    "\n",
    "Here the test data should go in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(input_data: pd.DataFrame) -> np.ndarray:\n",
    "    #Choosing features\n",
    "    feature_chosen_test = housing_df_test[[\"LotArea\" , \"Neighborhood\", \"TotalBsmtSF\", \"GrLivArea\",\"BldgType\",\"GarageArea\"]]\n",
    "    feature_chosen_test = feature_chosen_test.dropna()\n",
    "\n",
    "    #encoding\n",
    "    columns_to_encode = ['Neighborhood', 'BldgType']\n",
    "    encoder_unloaded = joblib.load(os.path.join (path, 'one_hot_encoder.joblib'))\n",
    "    encoded_features = encoder_unloaded.fit_transform(feature_chosen_test[columns_to_encode])\n",
    "    categories = encoder_unloaded.categories_\n",
    "    encoded_columns = [f\"{column}_{category}\" for column, category_list in zip(columns_to_encode, categories) for category in category_list[1:]]\n",
    "    encoded_df = pd.DataFrame(encoded_features, columns=encoded_columns)\n",
    "    feature_chosen_test.drop(columns=columns_to_encode, inplace=True)\n",
    "    feature_chosen_test = pd.concat([feature_chosen_test, encoded_df], axis=1)\n",
    "\n",
    "    #Scaling and Model fitting\n",
    "    model_unload = joblib.load(os.path.join (path, 'model.joblib'))\n",
    "\n",
    "    feature_chosen_test.dropna(inplace=True)\n",
    "    scaler_unloaded = joblib.load(os.path.join(path, 'scaler.joblib'))\n",
    "    feature_chosen_test_transform = scaler_unloaded.fit_transform(feature_chosen_test)\n",
    "    y_pred_test = model_unload.predict(feature_chosen_test_transform)#scaler_unloaded.fit_transform(feature_chosen_test))\n",
    "    y_pred_test = np.abs(y_pred_test)\n",
    "    \n",
    "    return y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188350.1717458  210449.72746717 281556.7130024  276820.2725978\n",
      " 744162.50142964 274250.47099252 253917.21574973 259991.04374094\n",
      " 272361.17691418 176165.34572331 125994.7914119 ]\n"
     ]
    }
   ],
   "source": [
    "#Let's try it \n",
    "print (make_prediction(housing_df_test)[0:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Using the preprocessing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_refactored(data: pd.DataFrame) -> dict[str, str]:\n",
    "    result = {}\n",
    "    features_list = [\"LotArea\", \"Neighborhood\", \"TotalBsmtSF\", \"GrLivArea\", \"BldgType\", \"GarageArea\", \"SalePrice\"]\n",
    "    y = [\"SalePrice\"]\n",
    "    categorical_features = [\"Neighborhood\", \"BldgType\"]\n",
    "    is_test = False\n",
    "    new_data = feature_selection(data, is_test, features_list, y)\n",
    "    X_train_categorical, X_test_categorical, y_train, y_test = hot_encoding_func(new_data, is_test, categorical_features, y)\n",
    "    X_train_scaled, X_test_scaled, _, _ = scaling_func(new_data, is_test, categorical_features, y)\n",
    "\n",
    "    X_train_final = np.hstack((X_train_scaled, X_train_categorical))\n",
    "    X_test_final = np.hstack((X_test_scaled, X_test_categorical))\n",
    "\n",
    "    model = joblib.load(os.path.join(path, 'model.joblib'))\n",
    "    model.fit(X_train_final, y_train)\n",
    "    y_pred = model.predict(X_test_final)\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "\n",
    "    result['rmse'] = compute_rmsle(y_test, y_pred)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SADEK COMPUTER\\AppData\\Local\\Temp\\ipykernel_15428\\2129603656.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_selection.dropna(subset=features, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print (build_model_refactored (housing_df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_refactored(input_data: pd.DataFrame) -> np.ndarray:\n",
    "    features_list = [\"LotArea\", \"Neighborhood\", \"TotalBsmtSF\", \"GrLivArea\", \"BldgType\", \"GarageArea\"]\n",
    "    categorical_features = [\"Neighborhood\", \"BldgType\"]\n",
    "    is_test = True\n",
    " \n",
    "    # Feature selection\n",
    "    new_data = feature_selection(input_data, is_test, features_list, [])\n",
    "    # Encoding\n",
    "    new_data = hot_encoding_func(new_data, is_test, categorical_features, [])\n",
    "    # Scaling\n",
    "    new_data = scaling_func(new_data, is_test, categorical_features, [])\n",
    " \n",
    "    model_unload = joblib.load(os.path.join(path, 'model.joblib'))\n",
    "    y_pred_test = model_unload.predict(new_data)\n",
    "    y_pred_test = np.abs(y_pred_test)\n",
    " \n",
    "    return y_pred_test\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188350.1717458  210449.72746717 281556.7130024  276820.2725978\n",
      " 744162.50142964 274250.47099252 253917.21574973 259991.04374094\n",
      " 272361.17691418 176165.34572331 125994.7914119 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SADEK COMPUTER\\AppData\\Local\\Temp\\ipykernel_15428\\75641688.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_selection.dropna(subset=features, inplace=True)\n",
      "C:\\Users\\SADEK COMPUTER\\AppData\\Local\\Temp\\ipykernel_15428\\75641688.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.drop(columns=categorical_features, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print (make_prediction_refactored(housing_df_test)[0:11])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
